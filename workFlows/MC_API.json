{
  "3": {
    "inputs": {
      "seed": 888716118307262,
      "steps": 30,
      "cfg": 8,
      "sampler_name": "euler_ancestral",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "4",
        0
      ],
      "positive": [
        "15",
        0
      ],
      "negative": [
        "15",
        1
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "1.5/LEOSAM HelloWorld Êñ∞‰∏ñÁïå _ SDXLÂ§ßÊ®°Âûã_v7.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "width": [
        "28",
        1
      ],
      "height": [
        "28",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "18",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": [
        "18",
        1
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "14": {
    "inputs": {
      "image": "#14 (1).jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "15": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "control_net": [
        "16",
        0
      ],
      "image": [
        "14",
        0
      ],
      "weights_override": [
        "17",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet üõÇüÖêüÖíüÖù"
    }
  },
  "16": {
    "inputs": {
      "control_net_name": "XL/TTPLANET_Controlnet_Tile_realistic_v2_fp16.safetensors"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "17": {
    "inputs": {
      "base_multiplier": 0.85,
      "flip_weights": false,
      "uncond_multiplier": 1
    },
    "class_type": "ScaledSoftControlNetWeights",
    "_meta": {
      "title": "Scaled Soft Weights üõÇüÖêüÖíüÖù"
    }
  },
  "18": {
    "inputs": {
      "text_positive": [
        "27",
        0
      ],
      "text_negative": [
        "23",
        0
      ],
      "style": "sai-cinematic",
      "log_prompt": true,
      "style_positive": true,
      "style_negative": true
    },
    "class_type": "SDXLPromptStyler",
    "_meta": {
      "title": "SDXL Prompt Styler"
    }
  },
  "23": {
    "inputs": {
      "string": "anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured, (worst quality:1.3), (low quality:1.3), (normal quality:1.3), lowres, bad anatomy,"
    },
    "class_type": "String Literal",
    "_meta": {
      "title": "String Literal"
    }
  },
  "27": {
    "inputs": {
      "string": "A man is wearing a light blue denim shirt, a white t-shirt, and denim shorts. He is still wearing white sneakers. This shirt has a button down collar and long sleeves. This pair of shorts looks very worn out. This outfit is decorated with a pair of white sneakers on the feet. The background is a deep blue sky and a gravel road."
    },
    "class_type": "String Literal",
    "_meta": {
      "title": "String Literal"
    }
  },
  "28": {
    "inputs": {
      "width": [
        "29",
        0
      ],
      "height": [
        "29",
        0
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 32,
      "image": [
        "14",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "29": {
    "inputs": {
      "value": 1536
    },
    "class_type": "ImpactInt",
    "_meta": {
      "title": "ImpactInt"
    }
  },
  "34": {
    "inputs": {
      "sam_model": "sam_hq_vit_h (2.57GB)",
      "grounding_dino_model": "GroundingDINO_SwinT_OGC (694MB)",
      "threshold": 0.3,
      "detail_method": "VITMatte(local)",
      "detail_erode": 6,
      "detail_dilate": 6,
      "black_point": 0.15,
      "white_point": 0.99,
      "process_detail": true,
      "prompt": [
        "38",
        0
      ],
      "device": "cuda",
      "max_megapixels": 2,
      "cache_model": false,
      "image": [
        "94",
        0
      ]
    },
    "class_type": "LayerMask: SegmentAnythingUltra V2",
    "_meta": {
      "title": "LayerMask: SegmentAnythingUltra V2"
    }
  },
  "38": {
    "inputs": {
      "string": "clothes"
    },
    "class_type": "String Literal",
    "_meta": {
      "title": "String Literal"
    }
  },
  "87": {
    "inputs": {
      "images_a_x": 0,
      "images_a_y": 1,
      "images_b_x": 0,
      "images_b_y": 0,
      "background": "images_a",
      "container_size_type": "max",
      "method": "pair",
      "images_a": [
        "177",
        0
      ],
      "images_b": [
        "34",
        0
      ]
    },
    "class_type": "ImageCompositeRelative",
    "_meta": {
      "title": "ImageCompositeRelative"
    }
  },
  "94": {
    "inputs": {
      "width": [
        "95",
        0
      ],
      "height": [
        "95",
        0
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 32,
      "image": [
        "96",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "95": {
    "inputs": {
      "value": 1536
    },
    "class_type": "ImpactInt",
    "_meta": {
      "title": "ImpactInt"
    }
  },
  "96": {
    "inputs": {
      "image": "#96.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "106": {
    "inputs": {
      "outline_width": 20,
      "tapered_corners": true,
      "mask": [
        "108",
        0
      ]
    },
    "class_type": "OutlineMask",
    "_meta": {
      "title": "Outline Mask ‚ôæÔ∏èMixlab"
    }
  },
  "108": {
    "inputs": {
      "expand": 10,
      "tapered_corners": true,
      "mask": [
        "34",
        1
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "110": {
    "inputs": {
      "fitting": 1,
      "function": "image outpainting",
      "scale": 1,
      "start_at": 0,
      "end_at": 10000,
      "save_memory": "none",
      "model": [
        "112",
        0
      ],
      "vae": [
        "112",
        4
      ],
      "image": [
        "87",
        0
      ],
      "mask": [
        "106",
        0
      ],
      "powerpaint": [
        "116",
        0
      ],
      "clip": [
        "111",
        0
      ],
      "positive": [
        "112",
        1
      ],
      "negative": [
        "112",
        2
      ]
    },
    "class_type": "PowerPaint",
    "_meta": {
      "title": "PowerPaint"
    }
  },
  "111": {
    "inputs": {
      "base": "PowerPaint/model.fp16.safetensors",
      "powerpaint": "PowerPaint/pytorch_model.bin"
    },
    "class_type": "PowerPaintCLIPLoader",
    "_meta": {
      "title": "PowerPaint CLIP Loader"
    }
  },
  "112": {
    "inputs": {
      "ckpt_name": "1.5/juggernaut_reborn.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -1,
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "positive": "",
      "negative": "embedding:EasyNegativeV2, embedding:badhandv4, ",
      "token_normalization": "mean",
      "weight_interpretation": "A1111",
      "empty_latent_width": 512,
      "empty_latent_height": 512,
      "batch_size": 1
    },
    "class_type": "Efficient Loader",
    "_meta": {
      "title": "Efficient Loader"
    }
  },
  "113": {
    "inputs": {
      "seed": 318626491418167,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "110",
        0
      ],
      "positive": [
        "110",
        1
      ],
      "negative": [
        "110",
        2
      ],
      "latent_image": [
        "110",
        3
      ],
      "optional_vae": [
        "112",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "116": {
    "inputs": {
      "brushnet": "PowerPaint/diffusion_pytorch_model.safetensors",
      "dtype": "float16"
    },
    "class_type": "BrushNetLoader",
    "_meta": {
      "title": "BrushNet Loader"
    }
  },
  "134": {
    "inputs": {
      "upscale_by": [
        "139",
        0
      ],
      "seed": 167391497513293,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "euler_ancestral",
      "scheduler": "karras",
      "denoise": 0.35000000000000003,
      "mode_type": "Linear",
      "tile_width": 1024,
      "tile_height": 1024,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": "enable",
      "tiled_decode": false,
      "image": [
        "113",
        5
      ],
      "model": [
        "4",
        0
      ],
      "positive": [
        "150",
        0
      ],
      "negative": [
        "150",
        1
      ],
      "vae": [
        "4",
        2
      ],
      "upscale_model": [
        "136",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "136": {
    "inputs": {
      "model_name": "4x_NMKD-Siax_200k.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "137": {
    "inputs": {
      "control_net_name": "XL/TTPLANET_Controlnet_Tile_realistic_v2_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "138": {
    "inputs": {
      "text": [
        "27",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "139": {
    "inputs": {
      "Number": "2"
    },
    "class_type": "Float",
    "_meta": {
      "title": "Float"
    }
  },
  "143": {
    "inputs": {
      "text": "crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, uglg, painting, drawing, illustration, deformed, mutated",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "145": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": [
        "147",
        0
      ],
      "height": [
        "147",
        1
      ],
      "crop": "disabled",
      "image": [
        "113",
        5
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "146": {
    "inputs": {
      "color_fix": "Wavelet",
      "image": [
        "134",
        0
      ],
      "color_map_image": [
        "145",
        0
      ]
    },
    "class_type": "StableSRColorFix",
    "_meta": {
      "title": "StableSRColorFix"
    }
  },
  "147": {
    "inputs": {
      "image": [
        "134",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "GetImageSize"
    }
  },
  "150": {
    "inputs": {
      "strength": 0.7000000000000001,
      "start_percent": 0,
      "end_percent": 0.8,
      "positive": [
        "138",
        0
      ],
      "negative": [
        "143",
        0
      ],
      "control_net": [
        "137",
        0
      ],
      "image": [
        "113",
        5
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "168": {
    "inputs": {
      "text": [
        "184",
        0
      ],
      "clip": [
        "170",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "169": {
    "inputs": {
      "vae_name": "flux1-ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "170": {
    "inputs": {
      "clip_name1": "SD3/t5xxl_fp8_e4m3fn.safetensors",
      "clip_name2": "SD3/clip_l.safetensors",
      "type": "flux"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "171": {
    "inputs": {
      "unet_name": "flux1/flux1-dev.sft",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "172": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "173": {
    "inputs": {
      "model": [
        "171",
        0
      ],
      "conditioning": [
        "168",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "174": {
    "inputs": {
      "noise_seed": [
        "175",
        0
      ]
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "175": {
    "inputs": {
      "seed": 996502165900465
    },
    "class_type": "easy seed",
    "_meta": {
      "title": "EasySeed"
    }
  },
  "176": {
    "inputs": {
      "noise": [
        "174",
        0
      ],
      "guider": [
        "173",
        0
      ],
      "sampler": [
        "172",
        0
      ],
      "sigmas": [
        "178",
        0
      ],
      "latent_image": [
        "179",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "177": {
    "inputs": {
      "samples": [
        "176",
        0
      ],
      "vae": [
        "169",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "178": {
    "inputs": {
      "scheduler": "simple",
      "steps": 10,
      "denoise": 0.7000000000000001,
      "model": [
        "171",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "179": {
    "inputs": {
      "pixels": [
        "8",
        0
      ],
      "vae": [
        "169",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "183": {
    "inputs": {
      "text_input": "",
      "task": "region_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 612266725728525,
      "image": [
        "8",
        0
      ],
      "florence2_model": [
        "186",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "184": {
    "inputs": {
      "text1": [
        "185",
        0
      ],
      "text2": [
        "183",
        2
      ],
      "separator": ""
    },
    "class_type": "CR Text Concatenate",
    "_meta": {
      "title": "üî§ CR Text Concatenate"
    }
  },
  "185": {
    "inputs": {
      "prompt": ""
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  },
  "186": {
    "inputs": {
      "model": "microsoft/Florence-2-large",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "194": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "146",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}